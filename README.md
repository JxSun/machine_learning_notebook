## Machine Learning Notebook
此筆記本主要整理自國立台灣大學林軒田教授所講授之「機器學習基石」與「機器學習技法」課程。
內容同樣依照原課程之分類方式依序做記錄。
如果有參考其他課程或資料的話（如Stanford Univ.的Andrew Ng教授的Machine Learning課程），會儘量在適當的地方進行補充。

***

###機器學習基石
####Ch1. _When Can Machines Learn? [何時可以使用機器學習]_
1.1 The Learning Problem [機器學習問題]  
1.2 Learning to Answer Yes/No [二元分類]  
1.3 Types of Learning [各式機器學習問題]  
1.4 Feasibility of Learning [機器學習的可行性]

####Ch2. _Why Can Machines Learn? [為什麼機器可以學習]_
2.1 Training versus Testing [訓練與測試]  
2.2 Theory of Generalization [舉一反三的一般化理論]  
2.3 The VC Dimension [VC 維度]  
2.4 Noise and Error [雜訊一錯誤]

####Ch3. _How Can Machines Learn? [機器可以怎麼樣學習]_
3.1 Linear Regression [線性迴歸]  
3.2 Linear `Soft' Classification [軟性的線性分類]  
3.3 Linear Classification beyond Yes/No [二元分類以外的分類問題]  
3.4 Nonlinear Transformation [非線性轉換]

####Ch4. _How Can Machines Learn Better? [機器可以怎麼樣學得更好]_
4.1 Hazard of Overfitting [過度訓練的危險]  
4.2 Preventing Overfitting I: Regularization [避免過度訓練一：控制調適]  
4.3 Preventing Overfitting II: Validation [避免過度訓練二：自我檢測]  
4.4 Three Learning Principles [三個機器學習的重要原則]  

###機器學習技法
####Ch5. _Embedding Numerous Features [嵌入大量的特徵]_
5.1 Linear Support Vector Machine [線性支持向量機]  
5.2 Dual Support Vector Machine [對偶支持向量機]  
5.3 Kernel Support Vector Machine [核型支持向量機]  
5.4 Soft-Margin Support Vector Machine [軟式支持向量機]  
5.5 Kernel Logistic Regression [核型羅吉斯迴歸]  
5.6 Support Vector Regression [支持向量迴歸]  

####Ch6. _Combining Predictive Features [融合預測性的特徵]_
6.1 Bootstrap Aggregation [自助聚合法]  
6.2 Adaptive Boosting [漸次提昇法]  
6.3 Decision Tree [決策樹]  
6.4 Random Forest [隨機森林]  
6.5 Gradient Boosted Decision Tree [梯度提昇決策樹]  

####Ch7. _Distilling Hidden Features [萃取隱藏的特徵]_
7.1 Neural Network [類神經網路]  
7.2 Deep Learning [深度學習]  
7.3 Radial Basis Function Network [逕向基函數網路] 
7.4 Matrix Factorization [矩陣分解]  

####Ch8. _Summary [總結]_

***

###參考資料
1. 機器學習基石 (Machine Learning Foundations), https://www.coursera.org/course/ntumlone
2. 機器學習技法 (Machine Learning Techniques), https://www.coursera.org/course/ntumltwo
