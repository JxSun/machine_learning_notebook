# Linear Support Vector Machine

###1. [PLA]() (複習)
 - 假設在二維平面上有兩群點，PLA算出來的結果會是一條分割兩群資料的直線。
 - 因為PLA具有隨機性，所以每次求出來的可能不會是同一條。
 - 假設在這個假說集（Hypothesis set）中有一條最好的線，哪一條線是最好的呢？

###2. 最好的線
 - 圖1 圖2 圖3
  - 圖3是看起來是最好的
 - 依直覺來看，我們會認為有一條線（或是平面），在兩群資料之間擁有最大的邊界，這條線就會是最好的那條。
   - 以取樣的角度來看，我們的訓練資料（training data）是真實資料的一部分。假設在取樣過程中會有一定程度的誤差，最大邊界的線相對起來比較可以容忍誤差。
     - 圖
   - 以 overfitting 的角度來看。機器學習其實就是一個最佳化過程，在最佳化的時候，如果增加一些條件，我們可以把這些條件看成 [regulization](https://en.wikipedia.org/wiki/Regularization_%28mathematics%29)，這些條件就可以減少我們對於資料 overfitting 的產生。

###3. 來找邊界最大的線吧！
